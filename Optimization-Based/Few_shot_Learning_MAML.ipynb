{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMsF/nwv1qgT7CKMZmYf7Eh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Akhilesh-K-Yadav/Meta-Learning_Projects/blob/main/Optimization-Based/Few_shot_Learning_MAML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Implementation of model-agnostic meta-learning for Omniglot.***\n"
      ],
      "metadata": {
        "id": "g8Wrs2DZdjmL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "HfKZDX81uDyV"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "\n",
        "import google_drive_downloader as gdd\n",
        "import imageio\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import dataset, sampler, dataloader\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch import autograd\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils import tensorboard\n",
        "#import pdb\n",
        "\n",
        "NUM_TRAIN_CLASSES = 1100\n",
        "NUM_VAL_CLASSES = 100\n",
        "NUM_TEST_CLASSES = 423\n",
        "NUM_SAMPLES_PER_CLASS = 20\n",
        "\n",
        "NUM_INPUT_CHANNELS = 1\n",
        "NUM_HIDDEN_CHANNELS = 64\n",
        "KERNEL_SIZE = 3\n",
        "NUM_CONV_LAYERS = 4\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "SUMMARY_INTERVAL = 10\n",
        "SAVE_INTERVAL = 100\n",
        "LOG_INTERVAL = 10\n",
        "VAL_INTERVAL = LOG_INTERVAL * 5\n",
        "NUM_TEST_TASKS = 600\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BASE_PATH = './omniglot_resized'\n",
        "GDD_FILE_ID = '1iaSFXIYC3AB8q9K_M-oVMa4pmB7yKMtI'\n",
        "gdd.GoogleDriveDownloader.download_file_from_google_drive(\n",
        "                file_id=GDD_FILE_ID,\n",
        "                dest_path=f'{BASE_PATH}.zip',\n",
        "                unzip=True\n",
        "            )"
      ],
      "metadata": {
        "id": "0wpmJYdzuomL"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_image(file_path):\n",
        "    \"\"\"Loads and transforms an Omniglot image.\n",
        "    Args:\n",
        "        file_path (str): file path of image\n",
        "    Returns:\n",
        "        a Tensor containing image data\n",
        "            shape (1, 28, 28)\n",
        "    \"\"\"\n",
        "    x = imageio.imread(file_path)\n",
        "    x = torch.tensor(x, dtype=torch.float32).reshape([1, 28, 28])\n",
        "    x = x / 255.0\n",
        "    return 1 - x"
      ],
      "metadata": {
        "id": "X6o-P5CdvMsp"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class OmniglotDataset(dataset.Dataset):\n",
        "    \"\"\"Omniglot dataset for meta-learning.\n",
        "\n",
        "    Each element of the dataset is a task. A task is specified with a key,\n",
        "    which is a tuple of class indices (no particular order). The corresponding\n",
        "    value is the instantiated task, which consists of sampled (image, label)\n",
        "    pairs.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_support, num_query):\n",
        "        \"\"\"Inits OmniglotDataset.\n",
        "\n",
        "        Args:\n",
        "            num_support (int): number of support examples per class\n",
        "            num_query (int): number of query examples per class\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        # get all character folders\n",
        "        self._character_folders = glob.glob(\n",
        "            os.path.join(BASE_PATH, '*/*/'))\n",
        "        assert len(self._character_folders) == (\n",
        "            NUM_TRAIN_CLASSES + NUM_VAL_CLASSES + NUM_TEST_CLASSES\n",
        "        )\n",
        "\n",
        "        # shuffle characters\n",
        "        np.random.default_rng(0).shuffle(self._character_folders)\n",
        "\n",
        "        # check problem arguments\n",
        "        assert num_support + num_query <= NUM_SAMPLES_PER_CLASS\n",
        "        self._num_support = num_support\n",
        "        self._num_query = num_query\n",
        "\n",
        "    def __getitem__(self, class_idxs):\n",
        "        \"\"\"Constructs a task.\n",
        "\n",
        "        Data for each class is sampled uniformly at random without replacement.\n",
        "        The ordering of the labels corresponds to that of class_idxs.\n",
        "\n",
        "        Args:\n",
        "            class_idxs (tuple[int]): class indices that comprise the task\n",
        "\n",
        "        Returns:\n",
        "            images_support (Tensor): task support images\n",
        "                shape (num_way * num_support, channels, height, width)\n",
        "            labels_support (Tensor): task support labels\n",
        "                shape (num_way * num_support,)\n",
        "            images_query (Tensor): task query images\n",
        "                shape (num_way * num_query, channels, height, width)\n",
        "            labels_query (Tensor): task query labels\n",
        "                shape (num_way * num_query,)\n",
        "        \"\"\"\n",
        "        images_support, images_query = [], []\n",
        "        labels_support, labels_query = [], []\n",
        "\n",
        "        for label, class_idx in enumerate(class_idxs):\n",
        "            # get a class's examples and sample from them\n",
        "            all_file_paths = glob.glob(\n",
        "                os.path.join(self._character_folders[class_idx], '*.png')\n",
        "            )\n",
        "            sampled_file_paths = np.random.default_rng().choice(\n",
        "                all_file_paths,\n",
        "                size=self._num_support + self._num_query,\n",
        "                replace=False\n",
        "            )\n",
        "            images = [load_image(file_path) for file_path in sampled_file_paths]\n",
        "\n",
        "            # split sampled examples into support and query\n",
        "            images_support.extend(images[:self._num_support])\n",
        "            images_query.extend(images[self._num_support:])\n",
        "            labels_support.extend([label] * self._num_support)\n",
        "            labels_query.extend([label] * self._num_query)\n",
        "\n",
        "        # aggregate into tensors\n",
        "        images_support = torch.stack(images_support)  # shape (N*S, C, H, W)\n",
        "        labels_support = torch.tensor(labels_support)  # shape (N*S)\n",
        "        images_query = torch.stack(images_query)\n",
        "        labels_query = torch.tensor(labels_query)\n",
        "\n",
        "        return images_support, labels_support, images_query, labels_query\n"
      ],
      "metadata": {
        "id": "a8dqXXMiGEqV"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class OmniglotSampler(sampler.Sampler):\n",
        "    \"\"\"Samples task specification keys for an OmniglotDataset.\"\"\"\n",
        "\n",
        "    def __init__(self, split_idxs, num_way, num_tasks):\n",
        "\n",
        "      \"\"\"Inits OmniglotSampler.\n",
        "\n",
        "      Args:\n",
        "          split_idxs (range): indices that comprise the\n",
        "              training/validation/test split\n",
        "          num_way (int): number of classes per task\n",
        "          num_tasks (int): number of tasks to sample\n",
        "      \"\"\"\n",
        "      super().__init__(None)\n",
        "\n",
        "      self.split_idxs = split_idxs\n",
        "      self.num_way = num_way\n",
        "      self.num_tasks = num_tasks\n",
        "\n",
        "    def __iter__(self):\n",
        "      return (\n",
        "          np.random.default_rng().choice(\n",
        "              self.split_idxs,\n",
        "              size=self.num_way,\n",
        "              replace=False\n",
        "          ) for _ in range(self.num_tasks)\n",
        "      )\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_tasks"
      ],
      "metadata": {
        "id": "ogefBquxdV0g"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def identity(x):\n",
        "    return x\n",
        "\n",
        "def get_omniglot_dataloader(\n",
        "        split,\n",
        "        batch_size,\n",
        "        num_way,\n",
        "        num_support,\n",
        "        num_query,\n",
        "        num_tasks_per_epoch\n",
        "):\n",
        "    \"\"\"Returns a dataloader.DataLoader for Omniglot.\n",
        "\n",
        "    Args:\n",
        "        split (str): one of 'train', 'val', 'test'\n",
        "        batch_size (int): number of tasks per batch\n",
        "        num_way (int): number of classes per task\n",
        "        num_support (int): number of support examples per class\n",
        "        num_query (int): number of query examples per class\n",
        "        num_tasks_per_epoch (int): number of tasks before DataLoader is\n",
        "            exhausted\n",
        "    \"\"\"\n",
        "\n",
        "    if split == 'train':\n",
        "        split_idxs = range(NUM_TRAIN_CLASSES)\n",
        "    elif split == 'val':\n",
        "        split_idxs = range(\n",
        "            NUM_TRAIN_CLASSES,\n",
        "            NUM_TRAIN_CLASSES + NUM_VAL_CLASSES\n",
        "        )\n",
        "    elif split == 'test':\n",
        "        split_idxs = range(\n",
        "            NUM_TRAIN_CLASSES + NUM_VAL_CLASSES,\n",
        "            NUM_TRAIN_CLASSES + NUM_VAL_CLASSES + NUM_TEST_CLASSES\n",
        "        )\n",
        "    else:\n",
        "        raise ValueError\n",
        "\n",
        "    return dataloader.DataLoader(\n",
        "        dataset=OmniglotDataset(num_support, num_query),\n",
        "        batch_size=batch_size,\n",
        "        sampler=OmniglotSampler(split_idxs, num_way, num_tasks_per_epoch),\n",
        "        num_workers=2,\n",
        "        collate_fn=identity,\n",
        "        pin_memory=torch.cuda.is_available(),\n",
        "        drop_last=True\n",
        "    )"
      ],
      "metadata": {
        "id": "PbvVAMUy-4hY"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = imageio.imread(\"/content/omniglot_resized/Alphabet_of_the_Magi/character01/0709_01.png\")\n",
        "image.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TqXJUyu1HRWE",
        "outputId": "9d62f683-11d9-459c-ed91-43aee7ef8086"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-22-913cf8e1afe4>:1: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
            "  image = imageio.imread(\"/content/omniglot_resized/Alphabet_of_the_Magi/character01/0709_01.png\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "samples = get_omniglot_dataloader(\n",
        "        split='train',\n",
        "        batch_size=1,\n",
        "        num_way=4,\n",
        "        num_support=1,\n",
        "        num_query=1,\n",
        "        num_tasks_per_epoch=1\n",
        ")\n",
        "tasks = next(iter(samples))\n",
        "for task in tasks:\n",
        "  images_support, labels_support, images_query, labels_query = task\n",
        "images_support.shape, labels_support.shape, images_query.shape, labels_query.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwOIUtCOHmOJ",
        "outputId": "71166cd0-4307-4846-83a5-b20e5bb45f75"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-a6327f0e4a5e>:9: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
            "  x = imageio.imread(file_path)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([4, 1, 28, 28]),\n",
              " torch.Size([4]),\n",
              " torch.Size([4, 1, 28, 28]),\n",
              " torch.Size([4]))"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(images_support[0][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "zytM404OI-kT",
        "outputId": "ea46281a-87b7-458a-81f9-9c079cedadb3"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x79745093a470>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels_support"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWZ8ZeLtMjlL",
        "outputId": "e9889039-7081-4319-e904-fa0b02f31b73"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def score(logits, labels):\n",
        "    \"\"\"Returns the mean accuracy of a model's predictions on a set of examples.\n",
        "\n",
        "    Args:\n",
        "        logits (torch.Tensor): model predicted logits\n",
        "            shape (examples, classes)\n",
        "        labels (torch.Tensor): classification labels from 0 to num_classes - 1\n",
        "            shape (examples,)\n",
        "    \"\"\"\n",
        "\n",
        "    #pdb.set_trace()\n",
        "    assert logits.dim() == 2\n",
        "    assert labels.dim() == 1\n",
        "    assert logits.shape[0] == labels.shape[0]\n",
        "    y = torch.argmax(logits, dim=-1) == labels\n",
        "    y = y.type(torch.float)\n",
        "    return torch.mean(y).item()"
      ],
      "metadata": {
        "id": "uoQAD2PyOml3"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MAML:\n",
        "    \"\"\"Trains and assesses a MAML.\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "            self,\n",
        "            num_outputs,\n",
        "            num_inner_steps,\n",
        "            inner_lr,\n",
        "            learn_inner_lrs,\n",
        "            outer_lr,\n",
        "            log_dir\n",
        "    ):\n",
        "        \"\"\"Inits MAML.\n",
        "\n",
        "        The network consists of four convolutional blocks followed by a linear\n",
        "        head layer. Each convolutional block comprises a convolution layer, a\n",
        "        batch normalization layer, and ReLU activation.\n",
        "\n",
        "        Note that unlike conventional use, batch normalization is always done\n",
        "        with batch statistics, regardless of whether we are training or\n",
        "        evaluating. This technically makes meta-learning transductive, as\n",
        "        opposed to inductive.\n",
        "\n",
        "        Args:\n",
        "            num_outputs (int): dimensionality of output, i.e. number of classes\n",
        "                in a task\n",
        "            num_inner_steps (int): number of inner-loop optimization steps\n",
        "            inner_lr (float): learning rate for inner-loop optimization\n",
        "                If learn_inner_lrs=True, inner_lr serves as the initialization\n",
        "                of the learning rates.\n",
        "            learn_inner_lrs (bool): whether to learn the above\n",
        "            outer_lr (float): learning rate for outer-loop optimization\n",
        "            log_dir (str): path to logging directory\n",
        "        \"\"\"\n",
        "        meta_parameters = {}\n",
        "\n",
        "        # construct feature extractor\n",
        "        in_channels = NUM_INPUT_CHANNELS\n",
        "        for i in range(NUM_CONV_LAYERS):\n",
        "            meta_parameters[f'conv{i}'] = nn.init.xavier_uniform_(\n",
        "                torch.empty(\n",
        "                    NUM_HIDDEN_CHANNELS,\n",
        "                    in_channels,\n",
        "                    KERNEL_SIZE,\n",
        "                    KERNEL_SIZE,\n",
        "                    requires_grad=True,\n",
        "                    device=DEVICE\n",
        "                )\n",
        "            )\n",
        "            meta_parameters[f'b{i}'] = nn.init.zeros_(\n",
        "                torch.empty(\n",
        "                    NUM_HIDDEN_CHANNELS,\n",
        "                    requires_grad=True,\n",
        "                    device=DEVICE\n",
        "                )\n",
        "            )\n",
        "            in_channels = NUM_HIDDEN_CHANNELS\n",
        "\n",
        "        # construct linear head layer\n",
        "        meta_parameters[f'w{NUM_CONV_LAYERS}'] = nn.init.xavier_uniform_(\n",
        "            torch.empty(\n",
        "                num_outputs,\n",
        "                NUM_HIDDEN_CHANNELS,\n",
        "                requires_grad=True,\n",
        "                device=DEVICE\n",
        "            )\n",
        "        )\n",
        "        meta_parameters[f'b{NUM_CONV_LAYERS}'] = nn.init.zeros_(\n",
        "            torch.empty(\n",
        "                num_outputs,\n",
        "                requires_grad=True,\n",
        "                device=DEVICE\n",
        "            )\n",
        "        )\n",
        "\n",
        "        self._meta_parameters = meta_parameters\n",
        "        self._num_inner_steps = num_inner_steps\n",
        "        self._inner_lrs = {\n",
        "            k: torch.tensor(inner_lr, requires_grad=learn_inner_lrs)\n",
        "            for k in self._meta_parameters.keys()\n",
        "        }\n",
        "        self._outer_lr = outer_lr\n",
        "\n",
        "        self._optimizer = torch.optim.Adam(\n",
        "            list(self._meta_parameters.values()) +\n",
        "            list(self._inner_lrs.values()),\n",
        "            lr=self._outer_lr\n",
        "        )\n",
        "        self._log_dir = log_dir\n",
        "        os.makedirs(self._log_dir, exist_ok=True)\n",
        "\n",
        "        self._start_train_step = 0\n",
        "\n",
        "    def _forward(self, images, parameters):\n",
        "        \"\"\"Computes predicted classification logits.\n",
        "\n",
        "        Args:\n",
        "            images (Tensor): batch of Omniglot images\n",
        "                shape (num_images, channels, height, width)\n",
        "            parameters (dict[str, Tensor]): parameters to use for\n",
        "                the computation\n",
        "\n",
        "        Returns:\n",
        "            a Tensor consisting of a batch of logits\n",
        "                shape (num_images, classes)\n",
        "        \"\"\"\n",
        "        #pdb.set_trace()\n",
        "        x = images\n",
        "        for i in range(NUM_CONV_LAYERS):\n",
        "            x = F.conv2d(\n",
        "                input=x,\n",
        "                weight=parameters[f'conv{i}'],\n",
        "                bias=parameters[f'b{i}'],\n",
        "                stride=1,\n",
        "                padding='same'\n",
        "            )\n",
        "            x = F.batch_norm(x, None, None, training=True)\n",
        "            x = F.relu(x)\n",
        "        x = torch.mean(x, dim=[2, 3])\n",
        "        return F.linear(\n",
        "            input=x,\n",
        "            weight=parameters[f'w{NUM_CONV_LAYERS}'],\n",
        "            bias=parameters[f'b{NUM_CONV_LAYERS}']\n",
        "        )\n",
        "\n",
        "    def _inner_loop(self, images, labels, train):\n",
        "        \"\"\"Computes the adapted network parameters via the MAML inner loop.\n",
        "\n",
        "        Args:\n",
        "            images (Tensor): task support set inputs\n",
        "                shape (num_images, channels, height, width)\n",
        "            labels (Tensor): task support set outputs\n",
        "                shape (num_images,)\n",
        "            train (bool): whether we are training or evaluating (not necessary?)\n",
        "\n",
        "        Returns:\n",
        "            parameters (dict[str, Tensor]): adapted network parameters\n",
        "            accuracies (list[float]): support set accuracy over the course of\n",
        "                the inner loop, length num_inner_steps + 1\n",
        "        \"\"\"\n",
        "        #pdb.set_trace()\n",
        "        accuracies = []\n",
        "        parameters = {\n",
        "            k: torch.clone(v)\n",
        "            for k, v in self._meta_parameters.items()\n",
        "        }\n",
        "        # This method computes the inner loop (adaptation) procedure for one\n",
        "        # task. It also scores the model along the way.\n",
        "        # Populate accuracies and update parameters.\n",
        "        # F.cross_entropy to compute classification losses.\n",
        "        # score() to compute accuracies.\n",
        "\n",
        "        # here we are doing \\phi_i = \\theta - inner_lr * grad(\\theta, L, D_{tr})\n",
        "        for _ in range(self._num_inner_steps):\n",
        "            logits = self._forward(images, parameters)\n",
        "            loss = F.cross_entropy(logits, labels)\n",
        "\n",
        "            # create graph due to computing second order derivatives in MAML\n",
        "            gradients = autograd.grad(\n",
        "                loss, parameters.values(), create_graph=True)\n",
        "\n",
        "            # update parameters\n",
        "            for i in range(len(parameters.keys())):\n",
        "                k = list(parameters.keys())[i]\n",
        "                v = list(parameters.values())[i]\n",
        "                assert v.shape == gradients[i].shape, 'Not proper shape'\n",
        "\n",
        "                parameters[k] = v - self._inner_lrs[k] * gradients[i]\n",
        "\n",
        "            acc = score(logits, labels)\n",
        "            accuracies.append(acc)\n",
        "\n",
        "        final_logits = self._forward(images, parameters)\n",
        "        final_acc = score(final_logits, labels)\n",
        "        accuracies.append(final_acc)\n",
        "        return parameters, accuracies\n",
        "\n",
        "    def _outer_step(self, task_batch, train):\n",
        "        \"\"\"Computes the MAML loss and metrics on a batch of tasks.\n",
        "\n",
        "        Args:\n",
        "            task_batch (tuple): batch of tasks from an Omniglot DataLoader\n",
        "            train (bool): whether we are training or evaluating\n",
        "\n",
        "        Returns:\n",
        "            outer_loss (Tensor): mean MAML loss over the batch, scalar\n",
        "            accuracies_support (ndarray): support set accuracy over the\n",
        "                course of the inner loop, averaged over the task batch\n",
        "                shape (num_inner_steps + 1,)\n",
        "            accuracy_query (float): query set accuracy of the adapted\n",
        "                parameters, averaged over the task batch\n",
        "        \"\"\"\n",
        "        #pdb.set_trace()\n",
        "        outer_loss_batch = []\n",
        "        accuracies_support_batch = []\n",
        "        accuracy_query_batch = []\n",
        "        for task in task_batch:\n",
        "            images_support, labels_support, images_query, labels_query = task\n",
        "            images_support = images_support.to(DEVICE)\n",
        "            labels_support = labels_support.to(DEVICE)\n",
        "            images_query = images_query.to(DEVICE)\n",
        "            labels_query = labels_query.to(DEVICE)\n",
        "            # For a given task, use the _inner_loop method to adapt, then\n",
        "            # compute the MAML loss and other metrics.\n",
        "            # F.cross_entropy to compute classification losses.\n",
        "            # score() to compute accuracies.\n",
        "            # Populate outer_loss_batch, accuracies_support_batch,\n",
        "            # and accuracy_query_batch.\n",
        "\n",
        "            # computes \\phi_L\n",
        "            parameters, supp_accs = self._inner_loop(\n",
        "                images_support, labels_support, train)\n",
        "\n",
        "            # gets the loss w.r.t. \\phi_L\n",
        "            logits = self._forward(images_query, parameters)\n",
        "            loss = F.cross_entropy(logits, labels_query)\n",
        "            outer_loss_batch.append(loss)\n",
        "\n",
        "            accuracies_support_batch.append(supp_accs)\n",
        "            q_accs = score(logits, labels_query)\n",
        "            accuracy_query_batch.append(q_accs)\n",
        "\n",
        "        outer_loss = torch.mean(torch.stack(outer_loss_batch))\n",
        "        accuracies_support = np.mean(\n",
        "            accuracies_support_batch,\n",
        "            axis=0\n",
        "        )\n",
        "        accuracy_query = np.mean(accuracy_query_batch)\n",
        "        return outer_loss, accuracies_support, accuracy_query\n",
        "\n",
        "\n",
        "    def train(self, dataloader_train, dataloader_val, writer):\n",
        "        \"\"\"Train the MAML.\n",
        "\n",
        "        Consumes dataloader_train to optimize MAML meta-parameters\n",
        "        while periodically validating on dataloader_val, logging metrics, and\n",
        "        saving checkpoints.\n",
        "\n",
        "        Args:\n",
        "            dataloader_train (DataLoader): loader for train tasks\n",
        "            dataloader_val (DataLoader): loader for validation tasks\n",
        "            writer (SummaryWriter): TensorBoard logger\n",
        "        \"\"\"\n",
        "        print(f'Starting training at iteration {self._start_train_step}.')\n",
        "        for i_step, task_batch in enumerate(\n",
        "                dataloader_train,\n",
        "                start=self._start_train_step\n",
        "        ):\n",
        "            self._optimizer.zero_grad()\n",
        "            outer_loss, accuracies_support, accuracy_query = (\n",
        "                self._outer_step(task_batch, train=True)\n",
        "            )\n",
        "            outer_loss.backward()\n",
        "            self._optimizer.step()\n",
        "\n",
        "            if i_step % LOG_INTERVAL == 0:\n",
        "                print(\n",
        "                    f'Iteration {i_step}: '\n",
        "                    f'loss: {outer_loss.item():.3f}, '\n",
        "                    f'pre-adaptation support accuracy: '\n",
        "                    f'{accuracies_support[0]:.3f}, '\n",
        "                    f'post-adaptation support accuracy: '\n",
        "                    f'{accuracies_support[-1]:.3f}, '\n",
        "                    f'post-adaptation query accuracy: '\n",
        "                    f'{accuracy_query:.3f}'\n",
        "                )\n",
        "                writer.add_scalar('loss/train', outer_loss.item(), i_step)\n",
        "                writer.add_scalar(\n",
        "                    'train_accuracy/pre_adapt_support',\n",
        "                    accuracies_support[0],\n",
        "                    i_step\n",
        "                )\n",
        "                writer.add_scalar(\n",
        "                    'train_accuracy/post_adapt_support',\n",
        "                    accuracies_support[-1],\n",
        "                    i_step\n",
        "                )\n",
        "                writer.add_scalar(\n",
        "                    'train_accuracy/post_adapt_query',\n",
        "                    accuracy_query,\n",
        "                    i_step\n",
        "                )\n",
        "\n",
        "            if i_step % VAL_INTERVAL == 0:\n",
        "                losses = []\n",
        "                accuracies_pre_adapt_support = []\n",
        "                accuracies_post_adapt_support = []\n",
        "                accuracies_post_adapt_query = []\n",
        "                for val_task_batch in dataloader_val:\n",
        "                    outer_loss, accuracies_support, accuracy_query = (\n",
        "                        self._outer_step(val_task_batch, train=False)\n",
        "                    )\n",
        "                    losses.append(outer_loss.item())\n",
        "                    accuracies_pre_adapt_support.append(accuracies_support[0])\n",
        "                    accuracies_post_adapt_support.append(\n",
        "                        accuracies_support[-1])\n",
        "                    accuracies_post_adapt_query.append(accuracy_query)\n",
        "                loss = np.mean(losses)\n",
        "                accuracy_pre_adapt_support = np.mean(\n",
        "                    accuracies_pre_adapt_support\n",
        "                )\n",
        "                accuracy_post_adapt_support = np.mean(\n",
        "                    accuracies_post_adapt_support\n",
        "                )\n",
        "                accuracy_post_adapt_query = np.mean(\n",
        "                    accuracies_post_adapt_query\n",
        "                )\n",
        "                print(\n",
        "                    f'Validation: '\n",
        "                    f'loss: {loss:.3f}, '\n",
        "                    f'pre-adaptation support accuracy: '\n",
        "                    f'{accuracy_pre_adapt_support:.3f}, '\n",
        "                    f'post-adaptation support accuracy: '\n",
        "                    f'{accuracy_post_adapt_support:.3f}, '\n",
        "                    f'post-adaptation query accuracy: '\n",
        "                    f'{accuracy_post_adapt_query:.3f}'\n",
        "                )\n",
        "                writer.add_scalar('loss/val', loss, i_step)\n",
        "                writer.add_scalar(\n",
        "                    'val_accuracy/pre_adapt_support',\n",
        "                    accuracy_pre_adapt_support,\n",
        "                    i_step\n",
        "                )\n",
        "                writer.add_scalar(\n",
        "                    'val_accuracy/post_adapt_support',\n",
        "                    accuracy_post_adapt_support,\n",
        "                    i_step\n",
        "                )\n",
        "                writer.add_scalar(\n",
        "                    'val_accuracy/post_adapt_query',\n",
        "                    accuracy_post_adapt_query,\n",
        "                    i_step\n",
        "                )\n",
        "\n",
        "            if i_step % SAVE_INTERVAL == 0:\n",
        "                self._save(i_step)\n",
        "\n",
        "    def test(self, dataloader_test):\n",
        "        \"\"\"Evaluate the MAML on test tasks.\n",
        "\n",
        "        Args:\n",
        "            dataloader_test (DataLoader): loader for test tasks\n",
        "        \"\"\"\n",
        "        accuracies = []\n",
        "        for task_batch in dataloader_test:\n",
        "            _, _, accuracy_query = self._outer_step(task_batch, train=False)\n",
        "            accuracies.append(accuracy_query)\n",
        "        mean = np.mean(accuracies)\n",
        "        std = np.std(accuracies)\n",
        "        mean_95_confidence_interval = 1.96 * std / np.sqrt(NUM_TEST_TASKS)\n",
        "        print(\n",
        "            f'Accuracy over {NUM_TEST_TASKS} test tasks: '\n",
        "            f'mean {mean:.3f}, '\n",
        "            f'95% confidence interval {mean_95_confidence_interval:.3f}'\n",
        "        )\n",
        "\n",
        "    def load(self, checkpoint_step):\n",
        "        \"\"\"Loads a checkpoint.\n",
        "\n",
        "        Args:\n",
        "            checkpoint_step (int): iteration of checkpoint to load\n",
        "\n",
        "        Raises:\n",
        "            ValueError: if checkpoint for checkpoint_step is not found\n",
        "        \"\"\"\n",
        "        target_path = (\n",
        "            f'{os.path.join(self._log_dir, \"state\")}'\n",
        "            f'{checkpoint_step}.pt'\n",
        "        )\n",
        "        if os.path.isfile(target_path):\n",
        "            state = torch.load(target_path)\n",
        "            self._meta_parameters = state['meta_parameters']\n",
        "            self._inner_lrs = state['inner_lrs']\n",
        "            self._optimizer.load_state_dict(state['optimizer_state_dict'])\n",
        "            self._start_train_step = checkpoint_step + 1\n",
        "            print(f'Loaded checkpoint iteration {checkpoint_step}.')\n",
        "        else:\n",
        "            raise ValueError(\n",
        "                f'No checkpoint for iteration {checkpoint_step} found.'\n",
        "            )\n",
        "\n",
        "    def _save(self, checkpoint_step):\n",
        "        \"\"\"Saves parameters and optimizer state_dict as a checkpoint.\n",
        "\n",
        "        Args:\n",
        "            checkpoint_step (int): iteration to label checkpoint with\n",
        "        \"\"\"\n",
        "        optimizer_state_dict = self._optimizer.state_dict()\n",
        "        torch.save(\n",
        "            dict(meta_parameters=self._meta_parameters,\n",
        "                 inner_lrs=self._inner_lrs,\n",
        "                 optimizer_state_dict=optimizer_state_dict),\n",
        "            f'{os.path.join(self._log_dir, \"state\")}{checkpoint_step}.pt'\n",
        "        )\n",
        "        print('Saved checkpoint.')\n"
      ],
      "metadata": {
        "id": "aeQ39GcTQTAC"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def main():\n",
        "    num_way = 5\n",
        "    num_support = 1\n",
        "    num_query = 5\n",
        "    num_inner_steps = 1\n",
        "    inner_lr = 0.4\n",
        "    learn_inner_lrs = False\n",
        "    outer_lr = 0.001\n",
        "    batch_size = 5\n",
        "    checkpoint_step = -1\n",
        "    test = False\n",
        "    num_train_iterations = 15000\n",
        "\n",
        "    log_dir = None\n",
        "    if log_dir is None:\n",
        "        log_dir = f'./logs/maml/omniglot.way:{num_way}.support:{num_support}.query:{num_query}.inner_steps:{num_inner_steps}.inner_lr:{inner_lr}.learn_inner_lrs:{learn_inner_lrs}.outer_lr:{outer_lr}.batch_size:{batch_size}'\n",
        "    print(f'log_dir: {log_dir}')\n",
        "    writer = tensorboard.SummaryWriter(log_dir=log_dir)\n",
        "\n",
        "    maml = MAML(\n",
        "        num_way,\n",
        "        num_inner_steps,\n",
        "        inner_lr,\n",
        "        learn_inner_lrs,\n",
        "        outer_lr,\n",
        "        log_dir\n",
        "    )\n",
        "\n",
        "    if checkpoint_step > -1:\n",
        "        maml.load(checkpoint_step)\n",
        "    else:\n",
        "        print('Checkpoint loading skipped.')\n",
        "\n",
        "    if not test:\n",
        "        num_training_tasks = batch_size * (num_train_iterations -\n",
        "                                                checkpoint_step - 1)\n",
        "        print(\n",
        "            f'Training on {num_training_tasks} tasks with composition: '\n",
        "            f'num_way={num_way}, '\n",
        "            f'num_support={num_support}, '\n",
        "            f'num_query={num_query}'\n",
        "        )\n",
        "        dataloader_train = get_omniglot_dataloader(\n",
        "            'train',\n",
        "            batch_size,\n",
        "            num_way,\n",
        "            num_support,\n",
        "            num_query,\n",
        "            num_training_tasks\n",
        "        )\n",
        "        dataloader_val = get_omniglot_dataloader(\n",
        "            'val',\n",
        "            batch_size,\n",
        "            num_way,\n",
        "            num_support,\n",
        "            num_query,\n",
        "            batch_size * 4\n",
        "        )\n",
        "        maml.train(\n",
        "            dataloader_train,\n",
        "            dataloader_val,\n",
        "            writer\n",
        "        )\n",
        "    else:\n",
        "        print(\n",
        "            f'Testing on tasks with composition '\n",
        "            f'num_way={num_way}, '\n",
        "            f'num_support={num_support}, '\n",
        "            f'num_query={num_query}'\n",
        "        )\n",
        "        dataloader_test = get_omniglot_dataloader(\n",
        "            'test',\n",
        "            1,\n",
        "            num_way,\n",
        "            num_support,\n",
        "            num_query,\n",
        "            NUM_TEST_TASKS\n",
        "        )\n",
        "        maml.test(dataloader_test)\n"
      ],
      "metadata": {
        "id": "U7rxg6p8XdbJ"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJ3vxP-3NxvQ",
        "outputId": "12198aa0-f1f7-4aa7-c5cd-e0e812b223fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "log_dir: ./logs/maml/omniglot.way:5.support:1.query:5.inner_steps:1.inner_lr:0.4.learn_inner_lrs:False.outer_lr:0.001.batch_size:5\n",
            "Checkpoint loading skipped.\n",
            "Training on 75000 tasks with composition: num_way=5, num_support=1, num_query=5\n",
            "Starting training at iteration 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-a6327f0e4a5e>:9: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
            "  x = imageio.imread(file_path)\n",
            "<ipython-input-18-a6327f0e4a5e>:9: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
            "  x = imageio.imread(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0: loss: 1.457, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.600, post-adaptation query accuracy: 0.480\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-a6327f0e4a5e>:9: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
            "  x = imageio.imread(file_path)\n",
            "<ipython-input-18-a6327f0e4a5e>:9: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
            "  x = imageio.imread(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation: loss: 1.417, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.580, post-adaptation query accuracy: 0.448\n",
            "Saved checkpoint.\n",
            "Iteration 10: loss: 1.314, pre-adaptation support accuracy: 0.240, post-adaptation support accuracy: 0.640, post-adaptation query accuracy: 0.552\n",
            "Iteration 20: loss: 1.218, pre-adaptation support accuracy: 0.280, post-adaptation support accuracy: 0.800, post-adaptation query accuracy: 0.648\n",
            "Iteration 30: loss: 1.180, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.760, post-adaptation query accuracy: 0.536\n",
            "Iteration 40: loss: 1.130, pre-adaptation support accuracy: 0.160, post-adaptation support accuracy: 0.720, post-adaptation query accuracy: 0.552\n",
            "Iteration 50: loss: 1.163, pre-adaptation support accuracy: 0.160, post-adaptation support accuracy: 0.920, post-adaptation query accuracy: 0.632\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-a6327f0e4a5e>:9: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
            "  x = imageio.imread(file_path)\n",
            "<ipython-input-18-a6327f0e4a5e>:9: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
            "  x = imageio.imread(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation: loss: 1.080, pre-adaptation support accuracy: 0.160, post-adaptation support accuracy: 0.890, post-adaptation query accuracy: 0.680\n",
            "Iteration 60: loss: 1.049, pre-adaptation support accuracy: 0.240, post-adaptation support accuracy: 0.920, post-adaptation query accuracy: 0.672\n",
            "Iteration 70: loss: 1.174, pre-adaptation support accuracy: 0.160, post-adaptation support accuracy: 0.920, post-adaptation query accuracy: 0.616\n",
            "Iteration 80: loss: 1.013, pre-adaptation support accuracy: 0.080, post-adaptation support accuracy: 0.960, post-adaptation query accuracy: 0.776\n",
            "Iteration 90: loss: 0.978, pre-adaptation support accuracy: 0.360, post-adaptation support accuracy: 0.960, post-adaptation query accuracy: 0.776\n",
            "Iteration 100: loss: 1.104, pre-adaptation support accuracy: 0.040, post-adaptation support accuracy: 0.960, post-adaptation query accuracy: 0.688\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-a6327f0e4a5e>:9: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
            "  x = imageio.imread(file_path)\n",
            "<ipython-input-18-a6327f0e4a5e>:9: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
            "  x = imageio.imread(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation: loss: 1.006, pre-adaptation support accuracy: 0.220, post-adaptation support accuracy: 0.950, post-adaptation query accuracy: 0.696\n",
            "Saved checkpoint.\n",
            "Iteration 110: loss: 1.035, pre-adaptation support accuracy: 0.240, post-adaptation support accuracy: 0.960, post-adaptation query accuracy: 0.608\n",
            "Iteration 120: loss: 0.883, pre-adaptation support accuracy: 0.240, post-adaptation support accuracy: 0.920, post-adaptation query accuracy: 0.688\n",
            "Iteration 130: loss: 1.074, pre-adaptation support accuracy: 0.080, post-adaptation support accuracy: 1.000, post-adaptation query accuracy: 0.712\n",
            "Iteration 140: loss: 0.988, pre-adaptation support accuracy: 0.080, post-adaptation support accuracy: 0.920, post-adaptation query accuracy: 0.704\n",
            "Iteration 150: loss: 0.985, pre-adaptation support accuracy: 0.120, post-adaptation support accuracy: 1.000, post-adaptation query accuracy: 0.640\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-a6327f0e4a5e>:9: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
            "  x = imageio.imread(file_path)\n",
            "<ipython-input-18-a6327f0e4a5e>:9: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
            "  x = imageio.imread(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation: loss: 0.895, pre-adaptation support accuracy: 0.190, post-adaptation support accuracy: 0.940, post-adaptation query accuracy: 0.732\n",
            "Iteration 160: loss: 0.846, pre-adaptation support accuracy: 0.280, post-adaptation support accuracy: 1.000, post-adaptation query accuracy: 0.768\n",
            "Iteration 170: loss: 0.886, pre-adaptation support accuracy: 0.160, post-adaptation support accuracy: 0.960, post-adaptation query accuracy: 0.728\n",
            "Iteration 180: loss: 0.839, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 1.000, post-adaptation query accuracy: 0.768\n",
            "Iteration 190: loss: 0.726, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.960, post-adaptation query accuracy: 0.744\n",
            "Iteration 200: loss: 0.835, pre-adaptation support accuracy: 0.240, post-adaptation support accuracy: 0.960, post-adaptation query accuracy: 0.720\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-a6327f0e4a5e>:9: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
            "  x = imageio.imread(file_path)\n",
            "<ipython-input-18-a6327f0e4a5e>:9: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
            "  x = imageio.imread(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation: loss: 0.933, pre-adaptation support accuracy: 0.140, post-adaptation support accuracy: 0.990, post-adaptation query accuracy: 0.726\n",
            "Saved checkpoint.\n",
            "Iteration 210: loss: 0.927, pre-adaptation support accuracy: 0.320, post-adaptation support accuracy: 0.920, post-adaptation query accuracy: 0.704\n",
            "Iteration 220: loss: 0.847, pre-adaptation support accuracy: 0.120, post-adaptation support accuracy: 0.920, post-adaptation query accuracy: 0.768\n",
            "Iteration 230: loss: 0.769, pre-adaptation support accuracy: 0.120, post-adaptation support accuracy: 1.000, post-adaptation query accuracy: 0.776\n",
            "Iteration 240: loss: 0.747, pre-adaptation support accuracy: 0.120, post-adaptation support accuracy: 1.000, post-adaptation query accuracy: 0.800\n",
            "Iteration 250: loss: 0.854, pre-adaptation support accuracy: 0.080, post-adaptation support accuracy: 1.000, post-adaptation query accuracy: 0.736\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-a6327f0e4a5e>:9: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
            "  x = imageio.imread(file_path)\n",
            "<ipython-input-18-a6327f0e4a5e>:9: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
            "  x = imageio.imread(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation: loss: 0.836, pre-adaptation support accuracy: 0.220, post-adaptation support accuracy: 0.950, post-adaptation query accuracy: 0.726\n",
            "Iteration 260: loss: 0.760, pre-adaptation support accuracy: 0.240, post-adaptation support accuracy: 1.000, post-adaptation query accuracy: 0.768\n",
            "Iteration 270: loss: 0.845, pre-adaptation support accuracy: 0.160, post-adaptation support accuracy: 1.000, post-adaptation query accuracy: 0.744\n",
            "Iteration 280: loss: 0.718, pre-adaptation support accuracy: 0.160, post-adaptation support accuracy: 1.000, post-adaptation query accuracy: 0.824\n",
            "Iteration 290: loss: 0.678, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.920, post-adaptation query accuracy: 0.824\n",
            "Iteration 300: loss: 0.786, pre-adaptation support accuracy: 0.280, post-adaptation support accuracy: 1.000, post-adaptation query accuracy: 0.784\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-a6327f0e4a5e>:9: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
            "  x = imageio.imread(file_path)\n",
            "<ipython-input-18-a6327f0e4a5e>:9: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
            "  x = imageio.imread(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation: loss: 0.682, pre-adaptation support accuracy: 0.190, post-adaptation support accuracy: 0.970, post-adaptation query accuracy: 0.802\n",
            "Saved checkpoint.\n",
            "Iteration 310: loss: 0.719, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 1.000, post-adaptation query accuracy: 0.744\n",
            "Iteration 320: loss: 0.803, pre-adaptation support accuracy: 0.240, post-adaptation support accuracy: 1.000, post-adaptation query accuracy: 0.744\n",
            "Iteration 330: loss: 0.687, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 1.000, post-adaptation query accuracy: 0.768\n",
            "Iteration 340: loss: 0.785, pre-adaptation support accuracy: 0.320, post-adaptation support accuracy: 0.920, post-adaptation query accuracy: 0.712\n",
            "Iteration 350: loss: 0.738, pre-adaptation support accuracy: 0.320, post-adaptation support accuracy: 1.000, post-adaptation query accuracy: 0.800\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-a6327f0e4a5e>:9: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
            "  x = imageio.imread(file_path)\n",
            "<ipython-input-18-a6327f0e4a5e>:9: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
            "  x = imageio.imread(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation: loss: 0.731, pre-adaptation support accuracy: 0.120, post-adaptation support accuracy: 1.000, post-adaptation query accuracy: 0.782\n",
            "Iteration 360: loss: 0.666, pre-adaptation support accuracy: 0.160, post-adaptation support accuracy: 0.960, post-adaptation query accuracy: 0.768\n",
            "Iteration 370: loss: 0.566, pre-adaptation support accuracy: 0.320, post-adaptation support accuracy: 1.000, post-adaptation query accuracy: 0.880\n",
            "Iteration 380: loss: 0.634, pre-adaptation support accuracy: 0.120, post-adaptation support accuracy: 1.000, post-adaptation query accuracy: 0.816\n",
            "Iteration 390: loss: 0.756, pre-adaptation support accuracy: 0.160, post-adaptation support accuracy: 1.000, post-adaptation query accuracy: 0.696\n",
            "Iteration 400: loss: 0.510, pre-adaptation support accuracy: 0.160, post-adaptation support accuracy: 0.960, post-adaptation query accuracy: 0.872\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-a6327f0e4a5e>:9: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
            "  x = imageio.imread(file_path)\n",
            "<ipython-input-18-a6327f0e4a5e>:9: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
            "  x = imageio.imread(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation: loss: 0.644, pre-adaptation support accuracy: 0.140, post-adaptation support accuracy: 0.990, post-adaptation query accuracy: 0.814\n",
            "Saved checkpoint.\n",
            "Iteration 410: loss: 0.545, pre-adaptation support accuracy: 0.120, post-adaptation support accuracy: 1.000, post-adaptation query accuracy: 0.880\n",
            "Iteration 420: loss: 0.666, pre-adaptation support accuracy: 0.320, post-adaptation support accuracy: 1.000, post-adaptation query accuracy: 0.800\n",
            "Iteration 430: loss: 0.626, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 1.000, post-adaptation query accuracy: 0.840\n",
            "Iteration 440: loss: 0.714, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.960, post-adaptation query accuracy: 0.712\n",
            "Iteration 450: loss: 0.634, pre-adaptation support accuracy: 0.120, post-adaptation support accuracy: 1.000, post-adaptation query accuracy: 0.808\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-a6327f0e4a5e>:9: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
            "  x = imageio.imread(file_path)\n",
            "<ipython-input-18-a6327f0e4a5e>:9: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
            "  x = imageio.imread(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation: loss: 0.626, pre-adaptation support accuracy: 0.160, post-adaptation support accuracy: 0.990, post-adaptation query accuracy: 0.832\n",
            "Iteration 460: loss: 0.594, pre-adaptation support accuracy: 0.240, post-adaptation support accuracy: 1.000, post-adaptation query accuracy: 0.808\n",
            "Iteration 470: loss: 0.751, pre-adaptation support accuracy: 0.240, post-adaptation support accuracy: 0.920, post-adaptation query accuracy: 0.752\n",
            "Iteration 480: loss: 0.540, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 1.000, post-adaptation query accuracy: 0.824\n",
            "Iteration 490: loss: 0.547, pre-adaptation support accuracy: 0.360, post-adaptation support accuracy: 1.000, post-adaptation query accuracy: 0.832\n",
            "Iteration 500: loss: 0.533, pre-adaptation support accuracy: 0.240, post-adaptation support accuracy: 0.960, post-adaptation query accuracy: 0.840\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-a6327f0e4a5e>:9: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
            "  x = imageio.imread(file_path)\n",
            "<ipython-input-18-a6327f0e4a5e>:9: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
            "  x = imageio.imread(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation: loss: 0.661, pre-adaptation support accuracy: 0.190, post-adaptation support accuracy: 0.990, post-adaptation query accuracy: 0.800\n",
            "Saved checkpoint.\n",
            "Iteration 510: loss: 0.747, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.960, post-adaptation query accuracy: 0.672\n",
            "Iteration 520: loss: 0.616, pre-adaptation support accuracy: 0.080, post-adaptation support accuracy: 1.000, post-adaptation query accuracy: 0.864\n",
            "Iteration 530: loss: 0.629, pre-adaptation support accuracy: 0.160, post-adaptation support accuracy: 1.000, post-adaptation query accuracy: 0.792\n",
            "Iteration 540: loss: 0.677, pre-adaptation support accuracy: 0.080, post-adaptation support accuracy: 1.000, post-adaptation query accuracy: 0.760\n",
            "Iteration 550: loss: 0.597, pre-adaptation support accuracy: 0.160, post-adaptation support accuracy: 0.960, post-adaptation query accuracy: 0.752\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-a6327f0e4a5e>:9: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
            "  x = imageio.imread(file_path)\n",
            "<ipython-input-18-a6327f0e4a5e>:9: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
            "  x = imageio.imread(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation: loss: 0.561, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 1.000, post-adaptation query accuracy: 0.836\n",
            "Iteration 560: loss: 0.745, pre-adaptation support accuracy: 0.280, post-adaptation support accuracy: 1.000, post-adaptation query accuracy: 0.720\n",
            "Iteration 570: loss: 0.606, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 1.000, post-adaptation query accuracy: 0.776\n",
            "Iteration 580: loss: 0.702, pre-adaptation support accuracy: 0.120, post-adaptation support accuracy: 1.000, post-adaptation query accuracy: 0.832\n",
            "Iteration 590: loss: 0.513, pre-adaptation support accuracy: 0.160, post-adaptation support accuracy: 1.000, post-adaptation query accuracy: 0.848\n",
            "Iteration 600: loss: 0.565, pre-adaptation support accuracy: 0.240, post-adaptation support accuracy: 1.000, post-adaptation query accuracy: 0.816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-a6327f0e4a5e>:9: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
            "  x = imageio.imread(file_path)\n",
            "<ipython-input-18-a6327f0e4a5e>:9: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
            "  x = imageio.imread(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation: loss: 0.561, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.990, post-adaptation query accuracy: 0.830\n",
            "Saved checkpoint.\n",
            "Iteration 610: loss: 0.632, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.960, post-adaptation query accuracy: 0.800\n",
            "Iteration 620: loss: 0.636, pre-adaptation support accuracy: 0.160, post-adaptation support accuracy: 1.000, post-adaptation query accuracy: 0.816\n",
            "Iteration 630: loss: 0.400, pre-adaptation support accuracy: 0.240, post-adaptation support accuracy: 1.000, post-adaptation query accuracy: 0.888\n",
            "Iteration 640: loss: 0.646, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 1.000, post-adaptation query accuracy: 0.728\n",
            "Iteration 650: loss: 0.577, pre-adaptation support accuracy: 0.280, post-adaptation support accuracy: 1.000, post-adaptation query accuracy: 0.792\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-a6327f0e4a5e>:9: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
            "  x = imageio.imread(file_path)\n",
            "<ipython-input-18-a6327f0e4a5e>:9: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
            "  x = imageio.imread(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation: loss: 0.503, pre-adaptation support accuracy: 0.230, post-adaptation support accuracy: 1.000, post-adaptation query accuracy: 0.858\n",
            "Iteration 660: loss: 0.499, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.960, post-adaptation query accuracy: 0.864\n",
            "Iteration 670: loss: 0.571, pre-adaptation support accuracy: 0.120, post-adaptation support accuracy: 0.960, post-adaptation query accuracy: 0.800\n",
            "Iteration 680: loss: 0.622, pre-adaptation support accuracy: 0.160, post-adaptation support accuracy: 1.000, post-adaptation query accuracy: 0.776\n",
            "Iteration 690: loss: 0.570, pre-adaptation support accuracy: 0.360, post-adaptation support accuracy: 0.960, post-adaptation query accuracy: 0.768\n",
            "Iteration 700: loss: 0.500, pre-adaptation support accuracy: 0.400, post-adaptation support accuracy: 1.000, post-adaptation query accuracy: 0.848\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-a6327f0e4a5e>:9: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
            "  x = imageio.imread(file_path)\n",
            "<ipython-input-18-a6327f0e4a5e>:9: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
            "  x = imageio.imread(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation: loss: 0.526, pre-adaptation support accuracy: 0.240, post-adaptation support accuracy: 1.000, post-adaptation query accuracy: 0.836\n",
            "Saved checkpoint.\n",
            "Iteration 710: loss: 0.473, pre-adaptation support accuracy: 0.160, post-adaptation support accuracy: 1.000, post-adaptation query accuracy: 0.864\n",
            "Iteration 720: loss: 0.580, pre-adaptation support accuracy: 0.280, post-adaptation support accuracy: 1.000, post-adaptation query accuracy: 0.784\n",
            "Iteration 730: loss: 0.492, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 1.000, post-adaptation query accuracy: 0.888\n",
            "Iteration 740: loss: 0.394, pre-adaptation support accuracy: 0.320, post-adaptation support accuracy: 1.000, post-adaptation query accuracy: 0.896\n",
            "Iteration 750: loss: 0.495, pre-adaptation support accuracy: 0.280, post-adaptation support accuracy: 1.000, post-adaptation query accuracy: 0.816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-a6327f0e4a5e>:9: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
            "  x = imageio.imread(file_path)\n",
            "<ipython-input-18-a6327f0e4a5e>:9: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
            "  x = imageio.imread(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation: loss: 0.487, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 1.000, post-adaptation query accuracy: 0.868\n",
            "Iteration 760: loss: 0.480, pre-adaptation support accuracy: 0.160, post-adaptation support accuracy: 1.000, post-adaptation query accuracy: 0.824\n",
            "Iteration 770: loss: 0.503, pre-adaptation support accuracy: 0.240, post-adaptation support accuracy: 1.000, post-adaptation query accuracy: 0.856\n",
            "Iteration 780: loss: 0.535, pre-adaptation support accuracy: 0.280, post-adaptation support accuracy: 1.000, post-adaptation query accuracy: 0.840\n",
            "Iteration 790: loss: 0.608, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.920, post-adaptation query accuracy: 0.736\n",
            "Iteration 800: loss: 0.484, pre-adaptation support accuracy: 0.240, post-adaptation support accuracy: 1.000, post-adaptation query accuracy: 0.832\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-a6327f0e4a5e>:9: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
            "  x = imageio.imread(file_path)\n",
            "<ipython-input-18-a6327f0e4a5e>:9: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
            "  x = imageio.imread(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation: loss: 0.455, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 1.000, post-adaptation query accuracy: 0.904\n",
            "Saved checkpoint.\n",
            "Iteration 810: loss: 0.537, pre-adaptation support accuracy: 0.120, post-adaptation support accuracy: 1.000, post-adaptation query accuracy: 0.832\n",
            "Iteration 820: loss: 0.425, pre-adaptation support accuracy: 0.240, post-adaptation support accuracy: 1.000, post-adaptation query accuracy: 0.928\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FpgUl3zJOAi-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}