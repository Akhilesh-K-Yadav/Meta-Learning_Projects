{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP8gbxmZ7K3b92d+8ak1C+Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Akhilesh-K-Yadav/Meta-Learning_Projects/blob/main/Optimization-Based/Few_shot_Learning_MAML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HfKZDX81uDyV"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "\n",
        "import google_drive_downloader as gdd\n",
        "import imageio\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import dataset, sampler, dataloader\n",
        "\n",
        "NUM_TRAIN_CLASSES = 1100\n",
        "NUM_VAL_CLASSES = 100\n",
        "NUM_TEST_CLASSES = 423\n",
        "NUM_SAMPLES_PER_CLASS = 20\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_BASE_PATH = './omniglot_resized'\n",
        "_GDD_FILE_ID = '1iaSFXIYC3AB8q9K_M-oVMa4pmB7yKMtI'\n",
        "gdd.GoogleDriveDownloader.download_file_from_google_drive(\n",
        "                file_id=_GDD_FILE_ID,\n",
        "                dest_path=f'{_BASE_PATH}.zip',\n",
        "                unzip=True\n",
        "            )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wpmJYdzuomL",
        "outputId": "6bcffb75-1630-4e47-97e6-78ef5df9631c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading 1iaSFXIYC3AB8q9K_M-oVMa4pmB7yKMtI into ./omniglot_resized.zip... Done.\n",
            "Unzipping...Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_image(file_path):\n",
        "    \"\"\"Loads and transforms an Omniglot image.\n",
        "    Args:\n",
        "        file_path (str): file path of image\n",
        "    Returns:\n",
        "        a Tensor containing image data\n",
        "            shape (1, 28, 28)\n",
        "    \"\"\"\n",
        "    x = imageio.imread(file_path)\n",
        "    x = torch.tensor(x, dtype=torch.float32).reshape([1, 28, 28])\n",
        "    x = x / 255.0\n",
        "    return 1 - x"
      ],
      "metadata": {
        "id": "X6o-P5CdvMsp"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class OmniglotDataset(dataset.Dataset):\n",
        "    \"\"\"Omniglot dataset for meta-learning.\n",
        "\n",
        "    Each element of the dataset is a task. A task is specified with a key,\n",
        "    which is a tuple of class indices (no particular order). The corresponding\n",
        "    value is the instantiated task, which consists of sampled (image, label)\n",
        "    pairs.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_support, num_query):\n",
        "        \"\"\"Inits OmniglotDataset.\n",
        "\n",
        "        Args:\n",
        "            num_support (int): number of support examples per class\n",
        "            num_query (int): number of query examples per class\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        # get all character folders\n",
        "        self._character_folders = glob.glob(\n",
        "            os.path.join(_BASE_PATH, '*/*/'))\n",
        "        assert len(self._character_folders) == (\n",
        "            NUM_TRAIN_CLASSES + NUM_VAL_CLASSES + NUM_TEST_CLASSES\n",
        "        )\n",
        "\n",
        "        # shuffle characters\n",
        "        np.random.default_rng(0).shuffle(self._character_folders)\n",
        "\n",
        "        # check problem arguments\n",
        "        assert num_support + num_query <= NUM_SAMPLES_PER_CLASS\n",
        "        self._num_support = num_support\n",
        "        self._num_query = num_query\n",
        "\n",
        "    def __getitem__(self, class_idxs):\n",
        "        \"\"\"Constructs a task.\n",
        "\n",
        "        Data for each class is sampled uniformly at random without replacement.\n",
        "        The ordering of the labels corresponds to that of class_idxs.\n",
        "\n",
        "        Args:\n",
        "            class_idxs (tuple[int]): class indices that comprise the task\n",
        "\n",
        "        Returns:\n",
        "            images_support (Tensor): task support images\n",
        "                shape (num_way * num_support, channels, height, width)\n",
        "            labels_support (Tensor): task support labels\n",
        "                shape (num_way * num_support,)\n",
        "            images_query (Tensor): task query images\n",
        "                shape (num_way * num_query, channels, height, width)\n",
        "            labels_query (Tensor): task query labels\n",
        "                shape (num_way * num_query,)\n",
        "        \"\"\"\n",
        "        images_support, images_query = [], []\n",
        "        labels_support, labels_query = [], []\n",
        "\n",
        "        for label, class_idx in enumerate(class_idxs):\n",
        "            # get a class's examples and sample from them\n",
        "            all_file_paths = glob.glob(\n",
        "                os.path.join(self._character_folders[class_idx], '*.png')\n",
        "            )\n",
        "            sampled_file_paths = np.random.default_rng().choice(\n",
        "                all_file_paths,\n",
        "                size=self._num_support + self._num_query,\n",
        "                replace=False\n",
        "            )\n",
        "            images = [load_image(file_path) for file_path in sampled_file_paths]\n",
        "\n",
        "            # split sampled examples into support and query\n",
        "            images_support.extend(images[:self._num_support])\n",
        "            images_query.extend(images[self._num_support:])\n",
        "            labels_support.extend([label] * self._num_support)\n",
        "            labels_query.extend([label] * self._num_query)\n",
        "\n",
        "        # aggregate into tensors\n",
        "        images_support = torch.stack(images_support)  # shape (N*S, C, H, W)\n",
        "        labels_support = torch.tensor(labels_support)  # shape (N*S)\n",
        "        images_query = torch.stack(images_query)\n",
        "        labels_query = torch.tensor(labels_query)\n",
        "\n",
        "        return images_support, labels_support, images_query, labels_query\n"
      ],
      "metadata": {
        "id": "a8dqXXMiGEqV"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class OmniglotSampler(sampler.Sampler):\n",
        "    \"\"\"Samples task specification keys for an OmniglotDataset.\"\"\"\n",
        "\n",
        "    def __init__(self, split_idxs, num_way, num_tasks):\n",
        "\n",
        "      \"\"\"Inits OmniglotSampler.\n",
        "\n",
        "      Args:\n",
        "          split_idxs (range): indices that comprise the\n",
        "              training/validation/test split\n",
        "          num_way (int): number of classes per task\n",
        "          num_tasks (int): number of tasks to sample\n",
        "      \"\"\"\n",
        "      super().__init__()\n",
        "\n",
        "      self.split_idxs = split_idxs\n",
        "      self.num_way = num_way\n",
        "      self.num_tasks = num_tasks\n",
        "\n",
        "    def __iter__(self):\n",
        "      return (\n",
        "          np.random.default_rng().choice(\n",
        "              self._split_idxs,\n",
        "              size=self._num_way,\n",
        "              replace=False\n",
        "          ) for _ in range(self._num_tasks)\n",
        "      )\n",
        "\n",
        "    def __len__(self):\n",
        "        return self._num_tasks"
      ],
      "metadata": {
        "id": "ogefBquxdV0g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def identity(x):\n",
        "    return x\n",
        "\n",
        "def get_omniglot_dataloader(\n",
        "        split,\n",
        "        batch_size,\n",
        "        num_way,\n",
        "        num_support,\n",
        "        num_query,\n",
        "        num_tasks_per_epoch\n",
        "):\n",
        "    \"\"\"Returns a dataloader.DataLoader for Omniglot.\n",
        "\n",
        "    Args:\n",
        "        split (str): one of 'train', 'val', 'test'\n",
        "        batch_size (int): number of tasks per batch\n",
        "        num_way (int): number of classes per task\n",
        "        num_support (int): number of support examples per class\n",
        "        num_query (int): number of query examples per class\n",
        "        num_tasks_per_epoch (int): number of tasks before DataLoader is\n",
        "            exhausted\n",
        "    \"\"\"\n",
        "\n",
        "    if split == 'train':\n",
        "        split_idxs = range(NUM_TRAIN_CLASSES)\n",
        "    elif split == 'val':\n",
        "        split_idxs = range(\n",
        "            NUM_TRAIN_CLASSES,\n",
        "            NUM_TRAIN_CLASSES + NUM_VAL_CLASSES\n",
        "        )\n",
        "    elif split == 'test':\n",
        "        split_idxs = range(\n",
        "            NUM_TRAIN_CLASSES + NUM_VAL_CLASSES,\n",
        "            NUM_TRAIN_CLASSES + NUM_VAL_CLASSES + NUM_TEST_CLASSES\n",
        "        )\n",
        "    else:\n",
        "        raise ValueError\n",
        "\n",
        "    return dataloader.DataLoader(\n",
        "        dataset=OmniglotDataset(num_support, num_query),\n",
        "        batch_size=batch_size,\n",
        "        sampler=OmniglotSampler(split_idxs, num_way, num_tasks_per_epoch),\n",
        "        num_workers=2,\n",
        "        collate_fn=identity,\n",
        "        pin_memory=torch.cuda.is_available(),\n",
        "        drop_last=True\n",
        "    )"
      ],
      "metadata": {
        "id": "PbvVAMUy-4hY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}